========= 512 

&& 1.3227038383483887, 0.5494482517242432, 1.875861406326294


&& 1.313272476196289, 0.5526795387268066, 1.8696551322937012

==========ours 

&& 1.3279166221618652, 0.5374150276184082, 1.8702151775360107


&& 1.367138385772705, 0.6595861911773682, 2.031623601913452


&& 1.4383957386016846, 0.7845516204833984, 2.227552652359009


&& 1.7072715759277344, 1.5156893730163574, 3.2271854877471924


&& 2.716576099395752, 3.862396478652954, 6.582707643508911

========= 1024 

&& 1.3185710906982422, 0.5448741912841797, 1.8819820880889893


&& 1.3256685733795166, 0.5783827304840088, 1.9183838367462158

==========ours 

&& 1.3498666286468506, 0.6267039775848389, 1.994797945022583


&& 1.3803610801696777, 0.7970845699310303, 2.195765733718872


&& 1.4495222568511963, 1.054201364517212, 2.522378444671631


&& 1.8468103408813477, 1.6246159076690674, 3.4898908138275146


&& 3.2341766357421875, 4.160333871841431, 7.412803649902344

========= 2048 

&& 1.3206651210784912, 0.582350492477417, 1.9777445793151855


&& 1.325178861618042, 0.5824546813964844, 1.982347011566162

==========ours 

&& 1.3681902885437012, 0.7007536888122559, 2.144595146179199


&& 1.394587516784668, 0.8762297630310059, 2.34622859954834


&& 1.4877521991729736, 1.2089660167694092, 2.776425838470459


&& 1.7922821044921875, 1.9440994262695312, 3.8117289543151855


&& 2.9836010932922363, 4.80621075630188, 7.865493535995483

========= 3072 

&& 1.378145456314087, 0.610342264175415, 2.1567869186401367


&& 1.378413200378418, 0.653343915939331, 2.2007758617401123

==========ours 

&& 1.4159977436065674, 0.86069655418396, 2.4459893703460693


&& 1.4669837951660156, 0.972588062286377, 2.608806848526001


&& 1.5512363910675049, 1.2672932147979736, 2.9855735301971436


&& 1.8295440673828125, 2.355844497680664, 4.354727268218994


&& 3.005711555480957, 5.722343683242798, 8.89691424369812

========= 4096 

&& 1.4400749206542969, 0.6841752529144287, 2.422987461090088


&& 1.4469945430755615, 0.6589794158935547, 2.4047951698303223

==========ours 

&& 1.461893081665039, 0.9919323921203613, 2.7532427310943604


&& 1.5442049503326416, 1.0950555801391602, 2.941342830657959


&& 1.6220066547393799, 1.4719574451446533, 3.3939995765686035


&& 1.8993396759033203, 2.898765802383423, 5.098266363143921


&& 3.230381488800049, 6.580742120742798, 10.111517906188965

========= 5120 

&& 1.514394998550415, 0.727271318435669, 2.7071259021759033


&& 1.5136733055114746, 0.7566959857940674, 2.737413167953491

==========ours 

&& 1.5629286766052246, 1.1482114791870117, 3.1774566173553467


&& 1.6271874904632568, 1.3393168449401855, 3.434335231781006


&& 1.711536169052124, 1.6832411289215088, 3.86299729347229


&& 2.017491102218628, 3.2062947750091553, 5.692135810852051


&& 3.108598232269287, 6.92905068397522, 10.504415273666382

========= 6144 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-no-cp.py", line 222, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-no-cp.py", line 196, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 4.50 GiB (GPU 0; 39.59 GiB total capacity; 8.45 GiB already allocated; 3.43 GiB free; 34.42 GiB reserved in total by PyTorch)

&& 1.592237949371338, 4.049659967422485, 6.316632986068726

==========ours 

&& 1.653533935546875, 4.476761102676392, 6.803486108779907


&& 1.7068595886230469, 1.586094617843628, 3.959628105163574


&& 1.813251256942749, 2.281115770339966, 4.767992973327637


&& 2.116424083709717, 3.6818900108337402, 6.470578908920288


&& 3.2755627632141113, 7.336025238037109, 11.288185596466064

========= 7168 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-no-cp.py", line 222, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-no-cp.py", line 196, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 3.06 GiB (GPU 0; 39.59 GiB total capacity; 16.81 GiB already allocated; 1.06 GiB free; 36.79 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-sq-cp.py", line 231, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-sq-cp.py", line 204, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/torch/utils/checkpoint.py", line 114, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 6.12 GiB (GPU 0; 39.59 GiB total capacity; 14.51 GiB already allocated; 3.48 GiB free; 34.37 GiB reserved in total by PyTorch)
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 246, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 148, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 231, in backward
    grad_input = padding_calc.resize_grad_in(f_info, grad_input)
  File "/home/yufan/labpytorch/uu/utils/padding_calc.py", line 320, in resize_grad_in
    grad_input = pd(grad_input)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/padding.py", line 23, in forward
    return F.pad(input, self.padding, 'constant', self.value)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 4001, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 1.54 GiB (GPU 0; 39.59 GiB total capacity; 29.60 GiB already allocated; 1.00 GiB free; 36.85 GiB reserved in total by PyTorch)

&& 1.8134582042694092, 1.903944969177246, 4.638746500015259


&& 1.916701078414917, 2.686105251312256, 5.521382093429565


&& 2.1639368534088135, 4.180689096450806, 7.26109766960144


&& 3.2747573852539062, 8.504557609558105, 12.699835777282715

========= 8192 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-no-cp.py", line 222, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-no-cp.py", line 189, in main
    out_ref = model_ref(input_ref)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-no-cp.py", line 159, in forward
    out = self.block(x)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/pooling.py", line 162, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/yufan/labpytorch/torch/_jit_internal.py", line 365, in fn
    return if_false(*args, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 659, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 39.59 GiB total capacity; 37.58 GiB already allocated; 198.19 MiB free; 37.60 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-sq-cp.py", line 231, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-ref-sq-cp.py", line 204, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/torch/utils/checkpoint.py", line 114, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 39.59 GiB total capacity; 32.66 GiB already allocated; 2.18 GiB free; 35.35 GiB reserved in total by PyTorch)
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 246, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 148, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/layers/maxpool2d.py", line 109, in backward
    grad_in = torch._C._nn.max_pool2d_with_indices_backward(grad_output, myctx.input, myctx.kernel_size, myctx.stride, myctx.padding, (1,1), False, myctx.arg_max)
RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 39.59 GiB total capacity; 35.70 GiB already allocated; 360.19 MiB free; 37.18 GiB reserved in total by PyTorch)

&& 1.9401397705078125, 2.318281650543213, 5.454593896865845


&& 2.0561506748199463, 2.947732448577881, 6.2034687995910645


&& 2.423835277557373, 4.649811744689941, 8.271162748336792


&& 3.4520998001098633, 9.517849683761597, 14.169391870498657

