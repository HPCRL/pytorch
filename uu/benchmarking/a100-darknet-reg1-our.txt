========= 512 
==========ours 

&&  1.896080732345581


&&  1.9087233543395996


&&  2.128178596496582


&&  3.031500816345215


&&  6.666555881500244

========= 1024 
==========ours 

&&  1.8700730800628662


&&  1.9777374267578125


&&  2.3022382259368896


&&  3.3900017738342285


&&  7.423043489456177

========= 2048 
==========ours 

&&  2.093174457550049


&&  2.282830238342285


&&  2.594856023788452


&&  3.7540483474731445


&&  7.663084268569946

========= 3072 
==========ours 

&&  2.3123981952667236


&&  2.541496992111206


&&  2.8833582401275635


&&  4.1421496868133545


&&  8.5022611618042

========= 4096 

&&  2.706108570098877


&&  2.8503081798553467


&&  3.3946824073791504


&&  4.846322774887085


&&  9.965080976486206

========= 5120 
==========ours 

&&  3.0735578536987305


&&  3.3005053997039795


&&  4.0008673667907715


&&  5.6240949630737305


&&  10.509417295455933

========= 6144 
==========ours 

&&  6.738795518875122


&&  3.8917171955108643


&&  4.7103681564331055


&&  6.304463863372803


&&  11.500502824783325

========= 7168 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 246, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 148, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 231, in backward
    grad_input = padding_calc.resize_grad_in(f_info, grad_input)
  File "/home/yufan/labpytorch/uu/utils/padding_calc.py", line 320, in resize_grad_in
    grad_input = pd(grad_input)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/padding.py", line 23, in forward
    return F.pad(input, self.padding, 'constant', self.value)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 4001, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 1.54 GiB (GPU 0; 39.59 GiB total capacity; 29.60 GiB already allocated; 1.00 GiB free; 36.85 GiB reserved in total by PyTorch)

&&  4.589884281158447


&&  5.411070346832275


&&  7.132724285125732


&&  12.457379341125488

========= 8192 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 246, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 148, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/layers/maxpool2d.py", line 109, in backward
    grad_in = torch._C._nn.max_pool2d_with_indices_backward(grad_output, myctx.input, myctx.kernel_size, myctx.stride, myctx.padding, (1,1), False, myctx.arg_max)
RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 39.59 GiB total capacity; 35.70 GiB already allocated; 360.19 MiB free; 37.18 GiB reserved in total by PyTorch)

&&  5.393307685852051


&&  6.136281728744507


&&  8.238330602645874


&&  13.86753797531128

========= 9216 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 246, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 120, in backward
    outputs = ctx.run_function(*detached_inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/sequential.py", line 8, in forward
    inputs = module(*inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 449, in forward
    out = tconv2d(input, self.weight, self.bias, self.stride,
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 145, in forward
    out = padding_calc.recreate_input_tile_f(info, out, next_id)
  File "/home/yufan/labpytorch/uu/utils/padding_calc.py", line 523, in recreate_input_tile_f
    input_tile = pd(input_tile)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/padding.py", line 23, in forward
    return F.pad(input, self.padding, 'constant', self.value)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 4001, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 2.54 GiB (GPU 0; 39.59 GiB total capacity; 31.72 GiB already allocated; 680.19 MiB free; 37.12 GiB reserved in total by PyTorch)

&&  6.281167030334473


&&  7.009930849075317


&&  9.15282416343689


&&  15.855677843093872

