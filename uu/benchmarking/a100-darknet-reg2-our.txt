========= 512 
==========ours 

&&  1.8712794780731201


&&  1.8675258159637451


&&  2.165126323699951


&&  3.0355775356292725


&&  6.675715684890747

========= 1024 
==========ours 

&&  1.9283888339996338


&&  1.9622738361358643


&&  2.356624126434326


&&  3.269195079803467


&&  7.318381309509277

========= 2048 
==========ours 

&&  2.045254707336426


&&  2.3672266006469727


&&  2.588627338409424


&&  3.7189812660217285


&&  7.836329698562622

========= 3072 
==========ours 

&&  2.323197841644287


&&  2.6320242881774902


&&  2.936636447906494


&&  4.156835317611694


&&  8.575061559677124

========= 4096 

&&  2.587045907974243


&&  2.8837571144104004


&&  3.3551478385925293


&&  4.813088655471802


&&  10.146399021148682

========= 5120 
==========ours 

&&  3.084787130355835


&&  3.301499366760254


&&  3.7756359577178955


&&  5.57309889793396


&&  10.035248041152954

========= 6144 
==========ours 

&&  6.725951671600342


&&  3.86873459815979


&&  4.4868385791778564


&&  6.609983921051025


&&  11.518168449401855

========= 7168 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 246, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 148, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 231, in backward
    grad_input = padding_calc.resize_grad_in(f_info, grad_input)
  File "/home/yufan/labpytorch/uu/utils/padding_calc.py", line 320, in resize_grad_in
    grad_input = pd(grad_input)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/padding.py", line 23, in forward
    return F.pad(input, self.padding, 'constant', self.value)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 4001, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 1.54 GiB (GPU 0; 39.59 GiB total capacity; 29.60 GiB already allocated; 1.00 GiB free; 36.85 GiB reserved in total by PyTorch)

&&  4.53923487663269


&&  5.4109320640563965


&&  7.235354900360107


&&  12.583426237106323

========= 8192 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 246, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 148, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/layers/maxpool2d.py", line 109, in backward
    grad_in = torch._C._nn.max_pool2d_with_indices_backward(grad_output, myctx.input, myctx.kernel_size, myctx.stride, myctx.padding, (1,1), False, myctx.arg_max)
RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 39.59 GiB total capacity; 35.70 GiB already allocated; 360.19 MiB free; 37.18 GiB reserved in total by PyTorch)

&&  5.381904602050781


&&  6.073781251907349


&&  8.07824969291687


&&  13.875918626785278

========= 9216 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 246, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/darknet19-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 120, in backward
    outputs = ctx.run_function(*detached_inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/sequential.py", line 8, in forward
    inputs = module(*inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 449, in forward
    out = tconv2d(input, self.weight, self.bias, self.stride,
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 145, in forward
    out = padding_calc.recreate_input_tile_f(info, out, next_id)
  File "/home/yufan/labpytorch/uu/utils/padding_calc.py", line 523, in recreate_input_tile_f
    input_tile = pd(input_tile)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/padding.py", line 23, in forward
    return F.pad(input, self.padding, 'constant', self.value)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 4001, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 2.54 GiB (GPU 0; 39.59 GiB total capacity; 31.72 GiB already allocated; 680.19 MiB free; 37.12 GiB reserved in total by PyTorch)

&&  6.315903663635254


&&  7.094302177429199


&&  9.424200773239136


&&  15.447757005691528

