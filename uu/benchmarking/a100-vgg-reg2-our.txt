========= 512 
==========ours 

&& 2.5290374755859375


&& 2.700869083404541


&& 2.8990321159362793


&& 3.780764579772949


&& 7.440720319747925

========= 1024 
==========ours 

&& 2.691713333129883


&& 2.83935284614563


&& 3.1514604091644287


&& 4.004859924316406


&& 7.609266519546509

========= 2048 
==========ours 

&& 3.1535212993621826


&& 3.268042802810669


&& 3.815460443496704


&& 4.917188405990601


&& 8.694005250930786

========= 3072 
==========ours 

&& 3.8985390663146973


&& 4.086328744888306


&& 4.5195817947387695


&& 6.139150857925415


&& 10.468708276748657

========= 4096 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 260, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 120, in backward
    outputs = ctx.run_function(*detached_inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/sequential.py", line 8, in forward
    inputs = module(*inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 449, in forward
    out = tconv2d(input, self.weight, self.bias, self.stride,
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 127, in forward
    out = F.conv2d(input, weight, bias, stride,
RuntimeError: CUDA out of memory. Tried to allocate 518.00 MiB (GPU 0; 39.59 GiB total capacity; 36.60 GiB already allocated; 328.19 MiB free; 37.46 GiB reserved in total by PyTorch)

&& 5.135822057723999


&& 5.654066562652588


&& 7.400550127029419

double free or corruption (out)
run-vgg.sh: line 51: 960789 Aborted                 (core dumped) python vgg16-our.py 4096 8 $NTIME

&& 12.579777717590332

========= 5120 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 260, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 120, in backward
    outputs = ctx.run_function(*detached_inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/sequential.py", line 8, in forward
    inputs = module(*inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 449, in forward
    out = tconv2d(input, self.weight, self.bias, self.stride,
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 145, in forward
    out = padding_calc.recreate_input_tile_f(info, out, next_id)
  File "/home/yufan/labpytorch/uu/utils/padding_calc.py", line 523, in recreate_input_tile_f
    input_tile = pd(input_tile)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/padding.py", line 23, in forward
    return F.pad(input, self.padding, 'constant', self.value)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 4001, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 3.13 GiB (GPU 0; 39.59 GiB total capacity; 34.80 GiB already allocated; 978.19 MiB free; 36.82 GiB reserved in total by PyTorch)

&& 6.734579086303711


&& 7.075260639190674


&& 8.867057800292969


&& 14.6390860080719

========= 6144 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 260, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 207, in main
    out = model(input, H, W, nTh, nTw )
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 157, in forward
    out_temp = checkpoint.checkpoint(self.block1, x, info, stream_structure[1], model_device, [nTh, nTw])
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 164, in checkpoint
    return cCheckpoint.apply(function, preserve, *args)
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 79, in forward
    outputs = run_function(*args)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/sequential.py", line 8, in forward
    inputs = module(*inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 449, in forward
    out = tconv2d(input, self.weight, self.bias, self.stride,
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 95, in forward
    out = F.conv2d(input, weight, bias, stride,
RuntimeError: CUDA out of memory. Tried to allocate 81.00 GiB (GPU 0; 39.59 GiB total capacity; 18.13 GiB already allocated; 15.53 GiB free; 22.79 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 260, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 148, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 2.53 GiB (GPU 0; 39.59 GiB total capacity; 22.13 GiB already allocated; 116.19 MiB free; 37.42 GiB reserved in total by PyTorch)

&& 8.815489530563354


&& 10.62703800201416


&& 17.50454044342041

========= 7168 
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 260, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 207, in main
    out = model(input, H, W, nTh, nTw )
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 157, in forward
    out_temp = checkpoint.checkpoint(self.block1, x, info, stream_structure[1], model_device, [nTh, nTw])
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 164, in checkpoint
    return cCheckpoint.apply(function, preserve, *args)
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 79, in forward
    outputs = run_function(*args)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/sequential.py", line 8, in forward
    inputs = module(*inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 449, in forward
    out = tconv2d(input, self.weight, self.bias, self.stride,
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 95, in forward
    out = F.conv2d(input, weight, bias, stride,
RuntimeError: CUDA out of memory. Tried to allocate 110.25 GiB (GPU 0; 39.59 GiB total capacity; 24.66 GiB already allocated; 7.33 GiB free; 30.99 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 260, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 148, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 210, in backward
    grad_input = torch.cudnn_convolution_backward_input(input_size, grad_output, weight_tensor, our_padding, stride, dilation, group, False, False, False)
RuntimeError: CUDA out of memory. Tried to allocate 864.00 MiB (GPU 0; 39.59 GiB total capacity; 32.12 GiB already allocated; 174.19 MiB free; 37.36 GiB reserved in total by PyTorch)

&& 10.739772319793701


&& 13.01181697845459


&& 19.88451361656189

