out torch.Size([1, 1, 4, 4])
Inside Conv2d backward
grad_output size :  torch.Size([1, 1, 4, 4])
grad_input size :  tensor([[[[ 0.5262,  0.1672,  0.1672, -0.1579],
          [ 0.1233, -0.0250, -0.0250, -0.0678],
          [ 0.1233, -0.0250, -0.0250, -0.0678],
          [-0.3013, -0.2372, -0.2372, -0.1485]]]], device='cuda:0')

&&&&&&&&&&&&&&&&&&& OUR forward &&&&&&&&&&&&&&&&&&&

!!!!!!! 1 1 4 4
++++++++++++++++++++++++++++++++++++++++++++++++
coord [0, 0]
AA 4 4
BB ph 1, none_tiled_input_shape (1, 1, 4, 4)
OH IH 4 4
bwd_out_shape  (3, 3)
fwd_out_shape  (2, 2)
OH IH 4 4
info  [{-11: fake[-11,-11]
 PI( <0,0,>,
 <otileshape 3,3,>,
 <padding >,
 <inpslidx 0,2,0,2,>, 
 <internal >, 
 <realidx 0,2,0,2,>, 
 <ndtsize >, 
  local_first False
 next_id -11
 numof tiles 2,2, ) 
, 140204469428576: conv2d140204469428576[0,0]
 PI( <0,0,>,
 <otileshape 3,3,>,
 <padding 1,0,1,0,>,
 <inpslidx 0,3,0,3,>, 
 <internal 0,1,0,1,>, 
 <realidx -1,3,-1,3,>, 
 <ndtsize 2,2,>, 
  local_first True
 next_id -99
 numof tiles 2,2, ) 
}, {-11: fake-grad-IN[-11,-11]
 PI( <0,0,>,
 <otileshape 2,2,>,
 <padding >,
 <inpslidx 0,1,0,1,>, 
 <internal >, 
 <realidx 0,1,0,1,>, 
 <ndtsize >, 
  local_first False
 next_id -101
 numof tiles 2,2, ) 
, 140204469428576: bk-conv2d140204469428576[0,0]
 PI( <0,0,>,
 <otileshape 3,3,>,
 <padding 1,0,1,0,>,
 <inpslidx 0,2,0,2,>, 
 <internal 0,1,0,1,>, 
 <realidx -1,2,-1,2,>, 
 <ndtsize >, 
  local_first False
 next_id -99
 numof tiles 2,2, ) 
}]
++++++++++++++++++++++++++++++++++++++++++++++++
coord [0, 1]
AA 4 4
BB ph 1, none_tiled_input_shape (1, 1, 4, 4)
OH IH 4 4
bwd_out_shape  (3, 3)
fwd_out_shape  (2, 2)
OH IH 4 4
info  [{-11: fake[-11,-11]
 PI( <0,1,>,
 <otileshape 3,3,>,
 <padding >,
 <inpslidx 1,3,0,2,>, 
 <internal >, 
 <realidx 1,3,0,2,>, 
 <ndtsize >, 
  local_first False
 next_id -11
 numof tiles 2,2, ) 
, 140204469428576: conv2d140204469428576[0,0]
 PI( <0,1,>,
 <otileshape 3,3,>,
 <padding 0,1,1,0,>,
 <inpslidx 0,3,0,3,>, 
 <internal 1,0,0,1,>, 
 <realidx 0,4,-1,3,>, 
 <ndtsize 2,2,>, 
  local_first True
 next_id -99
 numof tiles 2,2, ) 
}, {-11: fake-grad-IN[-11,-11]
 PI( <0,1,>,
 <otileshape 2,2,>,
 <padding >,
 <inpslidx 2,3,0,1,>, 
 <internal >, 
 <realidx 2,3,0,1,>, 
 <ndtsize >, 
  local_first False
 next_id -101
 numof tiles 2,2, ) 
, 140204469428576: bk-conv2d140204469428576[0,0]
 PI( <0,1,>,
 <otileshape 3,3,>,
 <padding 0,1,1,0,>,
 <inpslidx 1,3,0,2,>, 
 <internal 1,0,0,1,>, 
 <realidx 1,4,-1,2,>, 
 <ndtsize >, 
  local_first False
 next_id -99
 numof tiles 2,2, ) 
}]
++++++++++++++++++++++++++++++++++++++++++++++++
coord [1, 0]
AA 4 4
BB ph 1, none_tiled_input_shape (1, 1, 4, 4)
OH IH 4 4
bwd_out_shape  (3, 3)
fwd_out_shape  (2, 2)
OH IH 4 4
info  [{-11: fake[-11,-11]
 PI( <1,0,>,
 <otileshape 3,3,>,
 <padding >,
 <inpslidx 0,2,1,3,>, 
 <internal >, 
 <realidx 0,2,1,3,>, 
 <ndtsize >, 
  local_first False
 next_id -11
 numof tiles 2,2, ) 
, 140204469428576: conv2d140204469428576[0,0]
 PI( <1,0,>,
 <otileshape 3,3,>,
 <padding 1,0,0,1,>,
 <inpslidx 0,3,0,3,>, 
 <internal 0,1,1,0,>, 
 <realidx -1,3,0,4,>, 
 <ndtsize 2,2,>, 
  local_first True
 next_id -99
 numof tiles 2,2, ) 
}, {-11: fake-grad-IN[-11,-11]
 PI( <1,0,>,
 <otileshape 2,2,>,
 <padding >,
 <inpslidx 0,1,2,3,>, 
 <internal >, 
 <realidx 0,1,2,3,>, 
 <ndtsize >, 
  local_first False
 next_id -101
 numof tiles 2,2, ) 
, 140204469428576: bk-conv2d140204469428576[0,0]
 PI( <1,0,>,
 <otileshape 3,3,>,
 <padding 1,0,0,1,>,
 <inpslidx 0,2,1,3,>, 
 <internal 0,1,1,0,>, 
 <realidx -1,2,1,4,>, 
 <ndtsize >, 
  local_first False
 next_id -99
 numof tiles 2,2, ) 
}]
++++++++++++++++++++++++++++++++++++++++++++++++
coord [1, 1]
AA 4 4
BB ph 1, none_tiled_input_shape (1, 1, 4, 4)
OH IH 4 4
bwd_out_shape  (3, 3)
fwd_out_shape  (2, 2)
OH IH 4 4
info  [{-11: fake[-11,-11]
 PI( <1,1,>,
 <otileshape 3,3,>,
 <padding >,
 <inpslidx 1,3,1,3,>, 
 <internal >, 
 <realidx 1,3,1,3,>, 
 <ndtsize >, 
  local_first False
 next_id -11
 numof tiles 2,2, ) 
, 140204469428576: conv2d140204469428576[0,0]
 PI( <1,1,>,
 <otileshape 3,3,>,
 <padding 0,1,0,1,>,
 <inpslidx 0,3,0,3,>, 
 <internal 1,0,1,0,>, 
 <realidx 0,4,0,4,>, 
 <ndtsize 2,2,>, 
  local_first True
 next_id -99
 numof tiles 2,2, ) 
}, {-11: fake-grad-IN[-11,-11]
 PI( <1,1,>,
 <otileshape 2,2,>,
 <padding >,
 <inpslidx 2,3,2,3,>, 
 <internal >, 
 <realidx 2,3,2,3,>, 
 <ndtsize >, 
  local_first False
 next_id -101
 numof tiles 2,2, ) 
, 140204469428576: bk-conv2d140204469428576[0,0]
 PI( <1,1,>,
 <otileshape 3,3,>,
 <padding 0,1,0,1,>,
 <inpslidx 1,3,1,3,>, 
 <internal 1,0,1,0,>, 
 <realidx 1,4,1,4,>, 
 <ndtsize >, 
  local_first False
 next_id -99
 numof tiles 2,2, ) 
}]
SS input shape torch.Size([1, 1, 5, 5])
SS grad_output shape torch.Size([1, 1, 4, 4])
SS new_grad_out shape torch.Size([1, 1, 3, 3])
SS brefore reshape grad_input torch.Size([1, 1, 5, 5]) tensor([[[[ 0.1314,  0.4247,  0.2122,  0.0807, -0.2125],
          [ 0.3251,  0.5262,  0.1672, -0.1579, -0.3590],
          [ 0.0428,  0.1233, -0.0250, -0.0678, -0.1483],
          [-0.0886, -0.3013, -0.2372, -0.1485,  0.0642],
          [-0.2823, -0.4028, -0.1922,  0.0901,  0.2106]]]], device='cuda:0')
SS grad_input torch.Size([1, 1, 2, 2]) tensor([[[[-0.0250, -0.0678],
          [-0.2372, -0.1485]]]], device='cuda:0')
tsplit tile coor bkw??
big_grad_in tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.0250, -0.0678],
          [ 0.0000,  0.0000, -0.2372, -0.1485]]]], device='cuda:0')
SS input shape torch.Size([1, 1, 5, 5])
SS grad_output shape torch.Size([1, 1, 4, 4])
SS new_grad_out shape torch.Size([1, 1, 3, 3])
SS brefore reshape grad_input torch.Size([1, 1, 5, 5]) tensor([[[[ 0.1314,  0.4247,  0.2122,  0.0807, -0.2125],
          [ 0.3251,  0.5262,  0.1672, -0.1579, -0.3590],
          [ 0.0428,  0.1233, -0.0250, -0.0678, -0.1483],
          [-0.0886, -0.3013, -0.2372, -0.1485,  0.0642],
          [-0.2823, -0.4028, -0.1922,  0.0901,  0.2106]]]], device='cuda:0')
SS grad_input torch.Size([1, 1, 2, 2]) tensor([[[[ 0.1233, -0.0250],
          [-0.3013, -0.2372]]]], device='cuda:0')
tsplit tile coor bkw??
big_grad_in tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.1233, -0.0250, -0.0250, -0.0678],
          [-0.3013, -0.2372, -0.2372, -0.1485]]]], device='cuda:0')
SS input shape torch.Size([1, 1, 5, 5])
SS grad_output shape torch.Size([1, 1, 4, 4])
SS new_grad_out shape torch.Size([1, 1, 3, 3])
SS brefore reshape grad_input torch.Size([1, 1, 5, 5]) tensor([[[[ 0.1314,  0.4247,  0.2122,  0.0807, -0.2125],
          [ 0.3251,  0.5262,  0.1672, -0.1579, -0.3590],
          [ 0.0428,  0.1233, -0.0250, -0.0678, -0.1483],
          [-0.0886, -0.3013, -0.2372, -0.1485,  0.0642],
          [-0.2823, -0.4028, -0.1922,  0.0901,  0.2106]]]], device='cuda:0')
SS grad_input torch.Size([1, 1, 2, 2]) tensor([[[[ 0.1672, -0.1579],
          [-0.0250, -0.0678]]]], device='cuda:0')
tsplit tile coor bkw??
big_grad_in tensor([[[[ 0.0000,  0.0000,  0.1672, -0.1579],
          [ 0.0000,  0.0000, -0.0250, -0.0678],
          [ 0.1233, -0.0250, -0.0250, -0.0678],
          [-0.3013, -0.2372, -0.2372, -0.1485]]]], device='cuda:0')
SS input shape torch.Size([1, 1, 5, 5])
SS grad_output shape torch.Size([1, 1, 4, 4])
SS new_grad_out shape torch.Size([1, 1, 3, 3])
SS brefore reshape grad_input torch.Size([1, 1, 5, 5]) tensor([[[[ 0.1314,  0.4247,  0.2122,  0.0807, -0.2125],
          [ 0.3251,  0.5262,  0.1672, -0.1579, -0.3590],
          [ 0.0428,  0.1233, -0.0250, -0.0678, -0.1483],
          [-0.0886, -0.3013, -0.2372, -0.1485,  0.0642],
          [-0.2823, -0.4028, -0.1922,  0.0901,  0.2106]]]], device='cuda:0')
SS grad_input torch.Size([1, 1, 2, 2]) tensor([[[[ 0.5262,  0.1672],
          [ 0.1233, -0.0250]]]], device='cuda:0')
tsplit tile coor bkw??
big_grad_in tensor([[[[ 0.5262,  0.1672,  0.1672, -0.1579],
          [ 0.1233, -0.0250, -0.0250, -0.0678],
          [ 0.1233, -0.0250, -0.0250, -0.0678],
          [-0.3013, -0.2372, -0.2372, -0.1485]]]], device='cuda:0')

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

~~ check forward correctness ~~
-----------------------------------------

#### compare w1
-----------------------------------------

